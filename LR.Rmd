---
title: "UK / South Korea Trade: A Bayesian Analysis"
author: "Dominic Steinitz"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

I was intrigued by a
[tweet](https://twitter.com/PHammondMP/status/809628170471116800) by
the UK Chancellor of the Exchequer stating "exports have doubled over
the last year. Now worth nearly £11bn” and a
[tweet](https://twitter.com/JamesBerryMP/status/809341634378866689) by
Member of the UK Parliament stating South Korea "our second fastest
growing trading partner". Although I have never paid much attention to
trade statistics, both these statements seemed surprising. But these
days it's easy enough to verify such statements. It's also an
opportunity to use the techniques I believe data scientists in
(computer) game companies use to determine how much impact a new
feature has on the game's consumers.

One has to be slightly careful with trade statistics as they can just
be goods or goods and services. It's amusing to note that when I
provide software and analyses to US organisations, I am included in
the services exports from the UK to the US. Let's analyse goods first
before moving on to goods and services.

# Getting the Data

First let's get hold of the quarterly data from the UK [Office of
National Statistics](https://www.ons.gov.uk).

```{r}
ukstats <- "https://www.ons.gov.uk"
bop <- "economy/nationalaccounts/balanceofpayments"
ds <- "datasets/tradeingoodsmretsallbopeu2013timeseriesspreadsheet/current/mret.csv"

mycsv <- read.csv(paste(ukstats,"file?uri=",bop,ds,sep="/"),stringsAsFactors=FALSE)
```

Now we can find the columns that refer to Korea.

```{r}
ns <- which(grepl("Korea", names(mycsv)))
length(ns)
names(mycsv[ns[1]])
names(mycsv[ns[2]])
names(mycsv[ns[3]])
```

Now we can pull out the relevant information and create a data frame
of it.

```{r}
korean <- mycsv[grepl("Korea", names(mycsv))]
imports <- korean[grepl("Imports", names(korean))]
exports <- korean[grepl("Exports", names(korean))]
balance <- korean[grepl("Balance", names(korean))]

df <- data.frame(mycsv[grepl("Title", names(mycsv))],
                 imports,
                 exports,
                 balance)
colnames(df) <- c("Title", "Imports", "Exports", "Balance")

startQ <- which(grepl("1998 Q1",df$Title))
endQ <- which(grepl("2016 Q3",df$Title))
dfQ <- df[startQ:endQ,]
```

We can now plot the data.

```{r chunkname0, fig.align='center'}
library(zoo)
tab <- data.frame(kr=as.numeric(dfQ$Exports),
                  krLabs=as.numeric(as.Date(as.yearqtr(dfQ$Title,format='%Y Q%q'))))

library(ggplot2)
ggplot(tab, aes(x=as.Date(tab$krLabs), y=tab$kr)) + geom_line() +
    theme(legend.position="bottom") +
    ggtitle("UK Export to South Korea (Quarterly)") +
    theme(plot.title = element_text(hjust = 0.5)) +
    xlab("Date") +
    ylab("Value (£m)")
```

For good measure let's plot the annual data.

```{r chunkname1, fig.align='center'}
startY <- grep("^1998$",df$Title)
endY <- grep("^2015$",df$Title)
dfYear <- df[startY:endY,]

tabY <- data.frame(kr=as.numeric(dfYear$Exports),
                   krLabs=as.numeric(dfYear$Title))

ggplot(tabY, aes(x=tabY$krLabs, y=tabY$kr)) + geom_line() +
    theme(legend.position="bottom") +
    ggtitle("UK Export to South Korea (Annual)") +
    theme(plot.title = element_text(hjust = 0.5)) +
    xlab("Date") +
    ylab("Value (£m)")
```

And the monthly data.

```{r chunkname2, fig.align='center'}
startM <- grep("1998 JAN",df$Title)
endM <- grep("2016 OCT",df$Title)
dfMonth <- df[startM:endM,]

tabM <- data.frame(kr=as.numeric(dfMonth$Exports),
                   krLabs=as.numeric(as.Date(as.yearmon(dfMonth$Title,format='%Y %B'))))

ggplot(tabM, aes(x=as.Date(tabM$krLabs), y=tabM$kr)) + geom_line() +
    theme(legend.position="bottom") +
    ggtitle("UK Export to South Korea (Monthly)") +
    theme(plot.title = element_text(hjust = 0.5)) +
    xlab("Date") +
    ylab("Value (£m)")
```

It looks like some change took place in 2011 but nothing to suggest
either that "export have doubled over the last year" or that South
Korea is "our second fastest growing partner". That some sort of
change did happen is further supported by the fact a [Free Trade
Agreement](http://trade.ec.europa.eu/doclib/press/index.cfm?id=1521)
between the EU and Korea was put in place in 2011.

But was there really a change? And what sort of change was it?
Sometimes it's easy to imagine patterns where
there are none.

<center>![](http://imgs.xkcd.com/comics/linear_regression.png)</center>

With this warning in mind let us see if we can get a better feel from
the numbers as to what happened.

# The Model

Let us assume that the data for exports are approximated by a linear
function of time but that there is a change in the slope and the
offset at some point during observation.

$$
\begin{aligned}
\tau &\sim {\mathrm{Uniform}}(1, N) \\
\mu_1 &\sim \mathcal{N}(\mu_{\mu_1}, \sigma_{\mu_1}) \\
\gamma_1 &\sim \mathcal{N}(\mu_{\gamma_1}, \sigma_{\gamma_1}) \\
\sigma_1 &\sim \mathcal{N}(\mu_{\sigma_1}, \sigma_{\sigma_1}) \\
\mu_2 &\sim \mathcal{N}(\mu_{\mu_2}, \sigma_{\mu_2}) \\
\gamma_2 &\sim \mathcal{N}(\mu_{\gamma_2}, \sigma_{\gamma_2}) \\
\sigma_2 &\sim \mathcal{N}(\mu_{\sigma_2}, \sigma_{\sigma_2}) \\
y_i &\sim \begin{cases} \mathcal{N}(\mu_1 x_i + \gamma_1, \sigma_1) & \mbox{if } i  \lt \tau \\ \mathcal{N}(\mu_2 x_i + \gamma_2, \sigma_2), & \mbox{if } i  \geq \tau \end{cases}
\end{aligned}
$$

Since we are going to use [stan](http://mc-stan.org) to infer the
parameters for this model and stan cannot handle discrete parameters,
we need to marginalize out this (discrete) parameter. I hope to do the
same analysis with [LibBi](http://libbi.org) which seems more suited
to time series analysis and which I believe will not require such a
step.

Setting $D=\{y_i\}_{i = 1}^N$ we can calculate the likelihood

$$
\begin{aligned}
p(D \,|\, \mu_1, \gamma_1, \sigma_1, \mu_2, \gamma_2, \sigma_2)
&= \sum_{n=1}^N p(\tau, D \,|\, \mu_1, \gamma_1, \sigma_1, \mu_2, \gamma_2, \sigma_2) \\
&= \sum_{\tau=1}^N p(\tau) p(D \,|\, \tau, \mu_1, \sigma_1, \mu_2, \sigma_2) \\
&=\sum_{\tau=1}^N p(\tau) \prod_{i=1}^N p(y_i \,|\, \tau, \mu_1, \gamma_1, \sigma_1, \mu_2, \gamma_2, \sigma_2)
\end{aligned}
$$

stan operates on the log scale and thus requires the log likelihood

$$
\log p(D \,|\, \mu_1, \gamma_1, \sigma_1, \mu_2, \gamma_2, \sigma_2) =
\mathrm{log\_sum\_exp}_{\tau=1}^T
\big(
  \log \mathcal{U}(\tau \, | \, 1, T) \\
  + \sum_{i=1}^T \log \mathcal{N}(y_i \, | \, \nu_i, \rho_i)
  \big)
$$

where

$$
\begin{aligned}
  \nu_i &=
  \begin{cases}
    \mu_1 x_i + \gamma_1 & \mbox{if } i < \tau \\
    \mu_2 x_i + \gamma_2 & \mbox{if } i  \geq \tau
  \end{cases} \\
  \rho_i &=
  \begin{cases}
    \sigma_1 & \mbox{if } i < \tau \\
    \sigma_2 & \mbox{if } i  \geq \tau
  \end{cases}
\end{aligned}
$$

and where the log sum of exponents function is defined by

$$
\mathrm{\log\_sum\_exp}_{n=1}^N \, \alpha_n
=
\log \sum_{n=1}^N \exp(\alpha_n).
$$

The log sum of exponents function allows the model to be coded
directly in Stan using the built-in function \code{log\_sum\_exp},
which provides both arithmetic stability and efficiency for mixture
model calculations.

## Stan

Here's the model in stan. Sadly I haven't found a good way of divvying
up `.stan` files in a `.Rmd` file so that it still compiles.

~~~~{.CPP include="lr-changepoint.stan"}
~~~~

The above, although mimicking our mathematical model, has quadratic
complexity and we can use the trick in the
[stan manual](http://mc-stan.org/documentation) to make it linear
albeit with less clarity.

~~~~{.CPP include="lr-changepoint-ng.stan"}
~~~~

Let's run this model with the monthly data.

```{r}
NM <- nrow(tabM)
KM <- ncol(tabM)

yM <- tabM$kr
XM <- data.frame(tabM,rep(1,NM))[,2:3]

fitM <- stan(
    file = "lr-changepoint-ng.stan",
    data = list(x = XM$krLabs, y = yM, N = length(yM)),
    chains = 4,
    warmup = 1000,
    iter = 10000,
    cores = 4,
    refresh = 500,
    seed=42
)
```

Looking at the results below we see a multi-modal distribution so a
mean is not of much use.

```{r}
histData <- hist(extract(fitM)$tau,plot=FALSE,breaks=c(seq(1,length(yM),1)))
histData$counts
```

We can get a pictorial representation of the maxima so that the
multi-modality is even clearer.

```{r chunkname3, fig.align='center'}
min_indexes = which(diff(  sign(diff( c(0,histData$counts,0)))) == 2)
max_indexes = which(diff(  sign(diff( c(0,histData$counts,0)))) == -2)
modeData = data.frame(x=1:length(histData$counts),y=histData$counts)
min_locs = modeData[min_indexes,]
max_locs = modeData[max_indexes,]
plot(stockData$y, type="l")
points( min_locs, col="red", pch=19, cex=1  )
points( max_locs, col="green", pch=19, cex=1  )
```

My interpretation is that the evidence (data) says there is probably
no changepoint (a change at the beginning or end is no change) but
there might be a change at intermediate data points.

We can see
something strange (maybe a large single export?) happened at index
$`r max_locs$x[2]`$ which translates to $`r dfMonth$Title[max_locs$x[2]]`$.

The mode at index $`r max_locs$x[3]`$
which translates to $`r dfMonth$Title[max_locs$x[3]]`$ corresponds
roughly to the EU / Korea trade agreement.

Let us assume that there really was a material difference in trade at
this latter point. We can fit a linear regression before this point
and one after this point.

Here's the stan

~~~~{.CPP include="LR.stan"}
~~~~

And here's the R to fit the before and after data. We fit the model,
pull out the parameters for the regression and pull out the covariates


```{r}
N <- length(yM)
M <- max_locs$x[3]

fite <- stan(file = 'LR.stan',
             data = list(N = M, K = ncol(XM), y = yM[1:M], X = XM[1:M,]),
             pars=c("beta", "sigma"),
             chains=3,
             cores=3,
             iter=3000,
             warmup=1000,
             refresh=-1)

se <- extract(fite, pars = c("beta", "sigma"), permuted=TRUE)
estCovParamsE <- colMeans(se$beta)

fitl <- stan(file = 'LR.stan',
             data = list(N = N-M, K = ncol(XM), y = yM[(M+1):N], X = XM[(M+1):N,]),
             pars=c("beta", "sigma"),
             chains=3,
             cores=3,
             iter=3000,
             warmup=1000,
             refresh=-1)

sl <- extract(fitl, pars = c("beta", "sigma"), permuted=TRUE)
estCovParamsL <- colMeans(sl$beta)
```

Make predictions

```{r}
linRegPredsE <- data.matrix(XM) %*% estCovParamsE
linRegPredsL <- data.matrix(XM) %*% estCovParamsL
```

```{r chunkname4, fig.align='center'}
ggplot(tabM, aes(x=as.Date(tabM$krLabs), y=tabM$kr)) +
    geom_line(aes(x = as.Date(tabM$krLabs), y = tabM$kr, col = "Actual")) +
    geom_line(data=tabM[1:M,], aes(x = as.Date(tabM$krLabs[1:M]), y = linRegPredsE[(1:M),1], col = "Before (Early)")) +
    geom_line(data=tabM[(M+1):N,], aes(x = as.Date(tabM$krLabs[(M+1):N]), y = linRegPredsL[((M+1):N),1], col = "Prediction (After FTA)")) +
    theme(legend.position="bottom") +
    ggtitle("UK Export to South Korea (Monthly)") +
    theme(plot.title = element_text(hjust = 0.5)) +
    xlab("Date") +
    ylab("Value (£m)")
```

# An Intermediate Conclusion and Goods and Services (Pink Book)

So we didn't manage to substantiate either the Chancellor's claim, the
Member of Parliament's claim or the claim made in the report in The
Guardian.

But it may be that we can if we look at Goods and Services.

